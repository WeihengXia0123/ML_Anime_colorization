{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport os\nfrom torch.utils.data import random_split\nimport glob","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Import dataset and put into dataloader"},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n##### import CIFAR-10 dataset into trainset, testset# color dataset\ntransform_color = transforms.Compose([\n        transforms.ToTensor(),\n         transforms.Normalize((0.5), (0.5))\n    ])\n\nbatchSize = 20\n\ntrainset_color = torchvision.datasets.CIFAR10(root='../input/cifar10-python', train=True,\n                                         download=False, transform=transform_color)\ntrainloader_color = torch.utils.data.DataLoader(trainset_color, batch_size=batchSize,\n                                          shuffle=False, num_workers=2)\n\ntestset_color = torchvision.datasets.CIFAR10(root='../input/cifar10-python', train=False,\n                                       download=False, transform=transform_color)\ntestloader_color = torch.utils.data.DataLoader(testset_color, batch_size=batchSize,\n                                         shuffle=False, num_workers=2)\n\n# Number of GPUs available. Use 0 for CPU mode.\nngpu = 1\n# Decide which device we want to run on\ndevice = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\nprint(device)\n'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Splitting the training dataset for training and validation**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n##### import CIFAR-10 dataset into trainset, testset# color dataset\ntransform_color = transforms.Compose([\n        transforms.ToTensor(),\n         transforms.Normalize((0.5), (0.5))\n    ])\n\nbatchSize = 16\n\ntrainset_color = torchvision.datasets.CIFAR10(root='../input/cifar10-python', train=True,\n                                        download=False, transform=transform_color)\n\n\ntestset_color = torchvision.datasets.CIFAR10(root='../input/cifar10-python', train=False,\n                                       download=False, transform=transform_color)\n\ntorch.manual_seed(43)\nval_size = 5000\ntrain_size = len(trainset_color) - val_size\n\ntrainset_color, valset_color = random_split(trainset_color, [train_size, val_size])\nprint(len(trainset_color), len(valset_color))\n\nvalloader_color = torch.utils.data.DataLoader(valset_color, batch_size=batchSize,\n                                          shuffle=False, num_workers=2)\n\ntrainloader_color = torch.utils.data.DataLoader(trainset_color, batch_size=batchSize,\n                                          shuffle=False, num_workers=2)\ntestloader_color = torch.utils.data.DataLoader(testset_color, batch_size=batchSize,\n                                         shuffle=False, num_workers=2)\n# Number of GPUs available. Use 0 for CPU mode.\nngpu = 1\n# Decide which device we want to run on\ndevice = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\nprint(device)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Pre-processing: Convert all rgb images to gray images"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport cv2\n\n# functions to show an image\ndef imshow(img):\n    img = img / 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\n# get some random training images\ndataiter = iter(trainloader_color)\n\nimages_color, labels = dataiter.next()\n\n# show images\nimshow(torchvision.utils.make_grid(images_color))\n\n# show dataiter shape\nprint(images_color.shape)\n\nfor i, data_color in enumerate(trainloader_color, 0):\n    if (i==0):\n        images_color, labels_color = data_color\n        imshow(torchvision.utils.make_grid(images_color))\n        break\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# function to convert a rgb_img to gray_img\ndef rgb2gray(img):\n    rgb_img = img.transpose(1,2,0)\n    gray_img = cv2.cvtColor(rgb_img, cv2.COLOR_BGR2GRAY)\n    return gray_img\n\n# function to convert a batch of rgb images to gray images\ndef rgb2gray_batch(images):\n    rgb_images = np.array(images)    \n    \n    gray_images = []\n    for i in range(rgb_images.shape[0]):\n        img = rgb_images[i]\n        gray_img = rgb2gray(img)\n        gray_images.append(gray_img)\n    \n    gray_images = np.array(gray_images)\n    gray_images = torch.from_numpy(gray_images)\n    return gray_images\n        \nimages_gray = rgb2gray_batch(images_color)\n\n# show images\nimages_gray = images_gray.reshape(batchSize,1,32,32)\n\nimshow(torchvision.utils.make_grid(images_color))\nimshow(torchvision.utils.make_grid(images_gray))\nprint(\"images_gray shape: \", images_gray.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Define the MLP network"},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n\nclass MLP_net(nn.Module):\n    def __init__(self):\n        # Input layer is 1024, since CIFAR-10 gray_image is 32x32\n        # Output layer is 3072, since CIFAR-10 gray_image is 32x32x3\n        super(MLP_net, self).__init__()\n        \n        self.layer1 = nn.Linear(1024,512)\n        self.bn1 = nn.BatchNorm1d(512)\n        self.layer2 = nn.Linear(512,256)\n        self.bn2 = nn.BatchNorm1d(256)\n        self.layer3 = nn.Linear(256,128)\n        self.bn3 = nn.BatchNorm1d(128)\n        self.layer4 = nn.Linear(128,256)\n        self.bn4 = nn.BatchNorm1d(256)\n        self.layer5 = nn.Linear(256,512)\n        self.bn5 = nn.BatchNorm1d(512)\n        self.layer6 = nn.Linear(512,1024)\n        self.bn6 = nn.BatchNorm1d(1024)\n        self.layer7 = nn.Linear(1024,3072)\n\n        \n    def forward(self, x):\n        # convert tensor (4, 1, 32, 32) --> (4, 1*32*32)\n        x = x.view(x.size(0), -1)\n        \n        x = self.layer1(x)\n        x = self.bn1(x)\n        x = self.layer2(x)\n        x = self.bn2(x)\n        x = self.layer3(x)\n        x = self.bn3(x)\n        x = self.layer4(x)\n        x = self.bn4(x)\n        x = self.layer5(x)\n        x = self.bn5(x)\n        x = self.layer6(x)\n        x = self.bn6(x)\n        x = self.layer7(x)\n        return x\n\n'''\nclass MLP_net(nn.Module):\n    def __init__(self):\n        # Input layer is 1024, since CIFAR-10 gray_image is 32x32\n        # Output layer is 3072, since CIFAR-10 gray_image is 32x32x3\n        super(MLP_net, self).__init__()\n        \n        self.layer1 = nn.Linear(1024,512)\n        self.bn1 = nn.BatchNorm1d(512)\n        self.layer2 = nn.Linear(512,256)\n        self.bn2 = nn.BatchNorm1d(256)\n        self.layer3 = nn.Linear(256,128)\n        self.bn3 = nn.BatchNorm1d(128)\n        self.layer4 = nn.Linear(128,256)\n        self.bn4 = nn.BatchNorm1d(256)\n        self.layer5 = nn.Linear(256,512)\n        self.bn5 = nn.BatchNorm1d(512)\n        self.layer6 = nn.Linear(512,1024)\n        self.bn6 = nn.BatchNorm1d(1024)\n        self.layer7 = nn.Linear(1024,3072)\n        \n        /*\n\n        \n    def forward(self, x):\n        # convert tensor (4, 1, 32, 32) --> (4, 1*32*32)\n        x = x.view(x.size(0), -1)\n        \n        x = self.layer1(x)\n        x = self.bn1(x)\n        x = self.layer2(x)\n        x = self.bn2(x)\n        x = self.layer3(x)\n        x = self.bn3(x)\n        x = self.layer4(x)\n        x = self.bn4(x)\n        x = self.layer5(x)\n        x = self.bn5(x)\n        x = self.layer6(x)\n        x = self.bn6(x)\n        x = self.layer7(x)\n        return x\n\n'''\n\nmlp_net = MLP_net().to(device)\n\nprint(\"is cude: \", next(mlp_net.parameters()).is_cuda)\n\nif os.path.exists(\"./saved_model/mlp.pt\"):\n    print(\"Continue training from the saved model\")\n    mlp_net.load_state_dict(torch.load(\"./saved_model/mlp.pt\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Define the loss function and optimizer"},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.optim as optim\n\ncriterion = nn.MSELoss()\noptimizer = optim.SGD(mlp_net.parameters(), lr=0.001, momentum=0.9)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tensorboard to save all training output logs"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom torch.utils.tensorboard import SummaryWriter\n\n# Writer will output to ./runs/ directory by default\nwriter = SummaryWriter(\"./runs_mlp/\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train the network on 1 batch"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataiter = iter(trainloader_color)\n\nimages_color, labels = dataiter.next()\n\nhistory_loss=[]\nhistory_val_loss=[]\nfor epoch in range(8000):  # loop over the dataset multiple times\n    \n    running_loss = 0.0\n    num_training = 0\n    \n    # get the inputs; data is a list of [inputs, labels]\n    images_color, labels_color = data_color\n    images_gray = rgb2gray_batch(images_color)\n    # put data in gpu/cpu\n    images_color = images_color.to(device)\n    images_gray = images_gray.to(device)\n    # zero the parameter gradients\n    optimizer.zero_grad()\n\n    # forward + backward + optimize\n    # input: images_gray\n    images_gray = images_gray.view(images_gray.shape[0],-1)\n    # print(\"images_gray: \", images_gray.shape)\n    outputs = mlp_net(images_gray)\n    # change the shape of images_color: [batchSize,3,32,32] -> [batchSize,3072]\n    images_color = images_color.reshape(images_color.shape[0], -1) \n    loss = criterion(outputs, images_color)\n    loss.backward()\n    optimizer.step()\n    # print output statistics\n    running_loss += loss.item()\n    j = 1          # print every 200 mini-batches\n    if i % j == (j-1):     # print every 200 mini-batches\n        print(\"trainingloss:\",'[%d, %5d] loss: %.3f' %\n              (epoch + 1, i + 1, running_loss / j))\n        writer.add_scalar('Loss/train', running_loss/j, len(trainset_color)*epoch + i)\n        history_loss.append(running_loss / j)\n        running_loss = 0.0\n            \n    \n    running_val_loss = 0.0\n    # get the inputs; data is a list of [inputs, labels]\n    images_val_color, labels_val_color = data_val_color\n    images_val_gray = rgb2gray_batch(images_val_color)\n    # put data in gpu/cpu\n    images_val_color = images_val_color.to(device)\n    images_val_gray = images_val_gray.to(device)\n\n    # forward + backward + optimize\n    # input: images_val_gray\n    images_val_gray = images_val_gray.view(images_val_gray.shape[0],-1)\n    # print(\"images_val_gray: \", images_val_gray.shape)\n    outputs_val = mlp_net(images_val_gray)\n    # change the shape of images_val_color: [batchSize,3,32,32] -> [batchSize,3072]\n    images_val_color = images_val_color.reshape(images_val_color.shape[0], -1) \n\n    loss_val = criterion(outputs_val, images_val_color)\n\n    # print output statistics\n    running_val_loss += loss_val.item()\n\n\n    j = 1      # print every 200 mini-batches #TODO mettre le meme j que au dessus\n    if i % j == (j-1):     # print every 200 mini-batches\n        print(\"validation\",'[%d, %5d] loss: %.3f' %\n              (epoch + 1, i + 1, running_val_loss / j))\n        writer.add_scalar('Loss/val', running_val_loss/j, len(valset_color)*epoch + i)\n        history_val_loss.append(running_val_loss / j)\n\n        running_val_loss = 0.0\n        \nwriter.flush()\nwriter.close()\nprint('Finished Training')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nhistory_loss=[]\nhistory_val_loss=[]\nfor epoch in range(8000):  # loop over the dataset multiple times\n    \n    running_loss = 0.0\n    num_training = 0\n    \n    for i, data_color in enumerate(, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        images_color, labels_color = data_color\n        images_gray = rgb2gray_batch(images_color)\n        # put data in gpu/cpu\n        images_color = images_color.to(device)\n        images_gray = images_gray.to(device)\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        # input: images_gray\n        images_gray = images_gray.view(images_gray.shape[0],-1)\n        # print(\"images_gray: \", images_gray.shape)\n        outputs = mlp_net(images_gray)\n        # change the shape of images_color: [batchSize,3,32,32] -> [batchSize,3072]\n        images_color = images_color.reshape(images_color.shape[0], -1) \n        loss = criterion(outputs, images_color)\n        loss.backward()\n        optimizer.step()\n        # print output statistics\n        running_loss += loss.item()\n        j = 1            # print every 200 mini-batches\n        if i % j == (j-1):     # print every 200 mini-batches\n            print(\"trainingloss:\",'[%d, %5d] loss: %.3f' %\n                  (epoch + 1, i + 1, running_loss / j))\n            writer.add_scalar('Loss/train', running_loss/j, len(trainset_color)*epoch + i)\n            history_loss.append(running_loss / j)\n            running_loss = 0.0\n            \n    \n    running_val_loss = 0.0\n    for i, data_val_color in enumerate(valloader_color, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        images_val_color, labels_val_color = data_val_color\n        images_val_gray = rgb2gray_batch(images_val_color)\n        # put data in gpu/cpu\n        images_val_color = images_val_color.to(device)\n        images_val_gray = images_val_gray.to(device)\n        \n        # forward + backward + optimize\n        # input: images_val_gray\n        images_val_gray = images_val_gray.view(images_val_gray.shape[0],-1)\n        # print(\"images_val_gray: \", images_val_gray.shape)\n        outputs_val = mlp_net(images_val_gray)\n        # change the shape of images_val_color: [batchSize,3,32,32] -> [batchSize,3072]\n        images_val_color = images_val_color.reshape(images_val_color.shape[0], -1) \n        \n        loss_val = criterion(outputs_val, images_val_color)\n        \n        # print output statistics\n        running_val_loss += loss_val.item()\n        \n        \n        j = 1         # print every 200 mini-batches #TODO mettre le meme j que au dessus\n        if i % j == (j-1):     # print every 200 mini-batches\n            print(\"validation\",'[%d, %5d] loss: %.3f' %\n                  (epoch + 1, i + 1, running_val_loss / j))\n            writer.add_scalar('Loss/val', running_val_loss/j, len(valset_color)*epoch + i)\n            history_val_loss.append(running_val_loss / j)\n            \n            running_val_loss = 0.0\n        \nwriter.flush()\nwriter.close()\nprint('Finished Training')\n'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loss graphic evolution displayed (on training set and validation set)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining Figure\nf = plt.figure(figsize=(10,7))\nf.add_subplot()\n\n\n#Adding Subplot\nplt.plot(range(len(history_loss)), history_loss, label = \"loss\") # Loss curve for training set\nplt.plot(range(len(history_val_loss)), history_val_loss, label = \"val_loss\") # Loss curve for validation set\n\nplt.title(\"Loss Curve\",fontsize=18)\nplt.xlabel(\"Epochs\",fontsize=15)\nplt.ylabel(\"Loss\",fontsize=15)\nplt.grid(alpha=0.3)\nplt.legend()\nplt.savefig(\"Loss_curve.png\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Inference on train dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# get some random training images\n#dataiter = iter(trainloader_color)\n#images_color, labels_color = dataiter.next()\n\nfor i, data_color in enumerate(trainloader_color, 0):\n    if (i==0):\n        images_color, labels_color = data_color\n        imshow(torchvision.utils.make_grid(images_color))\n        break\n\nprint(\"images_color: \", images_color.shape)\n# show images\nimages_color_show = images_color.reshape(batchSize,3,32,32)\nimshow(torchvision.utils.make_grid(images_color_show.detach()))\n\nimages_gray = rgb2gray_batch(images_color)\n#print(\"images_gray: \", images_gray.shape)\n# show images\nimages_gray = images_gray.reshape(batchSize,1,32,32)\nimshow(torchvision.utils.make_grid(images_gray.detach()))\n\n# run inference on the network\n# oututs [4,3072]\nimages_gray = images_gray.to(device)\noutputs = mlp_net(images_gray)\n#print(outputs.shape)\n\nimages_color = outputs.reshape(batchSize,3,32,32)\n#print(images_color.shape)\n\nimages_color_1=images_color.reshape(images_color.shape[0], -1)\n\nloss_val = criterion(outputs, images_color_1)\n# print output statistics\nrunning_val_loss=0\nrunning_val_loss += loss_val.item()\n#print(loss_val.item())\n\nimages_gray = images_gray.to(\"cpu\")\nimages_color = images_color.to(\"cpu\")\nimshow(torchvision.utils.make_grid(images_color.detach()))\n\nimages_gray = images_gray.to(\"cpu\")\nimages_gray = torch.cat((images_gray, images_gray, images_gray), 1)\n\nfinal_result_display = torch.cat((images_color_show, images_gray, images_color), 0)\nimshow(torchvision.utils.make_grid(final_result_display.detach()))\n'''\nimshow(torchvision.utils.make_grid(images_color_show[1].detach()))\nimshow(torchvision.utils.make_grid(images_gray[1].detach()))\nimshow(torchvision.utils.make_grid(images_color[1].detach()))\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imshow(torchvision.utils.make_grid(images_color_show[11].detach()))\nimshow(torchvision.utils.make_grid(images_gray[11].detach()))\nimshow(torchvision.utils.make_grid(images_color[11].detach()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Save the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"if not os.path.exists('./saved_model'):\n    os.makedirs('./saved_model')\n    \ntorch.save(mlp_net.state_dict(), './saved_model/mlp.pt')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Inference on validation dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# get some random training images\n#dataiter = iter(valloader_color)\n#images_color, labels_color = dataiter.next()\nfor i, data_color in enumerate(valloader_color, 0):\n    if (i==4):\n        images_color, labels_color = data_color\n        imshow(torchvision.utils.make_grid(images_color))\n        break\n#print(\"images_color: \", images_color.shape)\n# show images\nimages_color_show = images_color.reshape(batchSize,3,32,32)\nimshow(torchvision.utils.make_grid(images_color_show.detach()))\n\nimages_gray = rgb2gray_batch(images_color)\n#print(\"images_gray: \", images_gray.shape)\n# show images\nimages_gray = images_gray.reshape(batchSize,1,32,32)\nimshow(torchvision.utils.make_grid(images_gray.detach()))\n\n# run inference on the network\n# oututs [4,3072]\nimages_gray = images_gray.to(device)\noutputs = mlp_net(images_gray)\n#print(outputs.shape)\n\nimages_color = outputs.reshape(batchSize,3,32,32)\n#print(images_color.shape)\n\nimages_gray = images_gray.to(\"cpu\")\nimages_color = images_color.to(\"cpu\")\nimshow(torchvision.utils.make_grid(images_color.detach()))\n\n\nimages_gray = images_gray.to(\"cpu\")\nimages_gray = torch.cat((images_gray, images_gray, images_gray), 1)\n\nfinal_result_display = torch.cat((images_color_show, images_gray, images_color), 0)\nimshow(torchvision.utils.make_grid(final_result_display.detach()))\n'''\nimshow(torchvision.utils.make_grid(images_color_show[5].detach()))\nimshow(torchvision.utils.make_grid(images_gray[5].detach()))\nimshow(torchvision.utils.make_grid(images_color[5].detach()))\n'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Inference on test dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# get some random training images\ndataiter = iter(testloader_color)\nimages_color, labels_color = dataiter.next()\n#print(\"images_color: \", images_color.shape)\n# show images\nimages_color_show = images_color.reshape(batchSize,3,32,32)\nimshow(torchvision.utils.make_grid(images_color_show.detach()))\n\nimages_gray = rgb2gray_batch(images_color)\n#print(\"images_gray: \", images_gray.shape)\n# show images\nimages_gray = images_gray.reshape(batchSize,1,32,32)\nimshow(torchvision.utils.make_grid(images_gray.detach()))\n\n# run inference on the network\n# oututs [batchSize,3072]\nimages_gray = images_gray.to(device)\noutputs = mlp_net(images_gray)\n#print(outputs.shape)\n\nimages_color = outputs.reshape(batchSize,3,32,32)\n#print(images_color.shape)\n\nimages_color = images_color.to(\"cpu\")\nimshow(torchvision.utils.make_grid(images_color.detach()))\n\nimages_gray = images_gray.to(\"cpu\")\nimages_gray = torch.cat((images_gray, images_gray, images_gray), 1)\n\nfinal_result_display = torch.cat((images_color_show, images_gray, images_color), 0)\nimshow(torchvision.utils.make_grid(final_result_display.detach()))\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}